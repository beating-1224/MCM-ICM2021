{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "equal-revision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1\n",
      " 1 0 1 1 1 0 1 1 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "path=r'E:/tupian/'\n",
    "#由于我们的数据集图片大小不一致，所以需要resize成统一大小 这里resize成100x100x3\n",
    "w=100\n",
    "h=100\n",
    "c=3\n",
    "#data 对应图片, label 是标签，roses 0,daisy 1,sunflowers 2,tulips 3,dandelion 4.\n",
    "def read_img(path):\n",
    "    imgs=[]\n",
    "    labels=[]\n",
    "    cate=[path+x for x in os.listdir(path) if os.path.isdir(path+x)]\n",
    "    for idx,i in enumerate(cate):\n",
    "        for j in os.listdir(i):\n",
    "            im = cv2.imread(i+'/'+j)\n",
    "            img = cv2.resize(im, (w, h))/255.\n",
    "            imgs.append(img)\n",
    "            labels.append(idx)\n",
    "    return np.asarray(imgs,np.float32),np.asarray(labels,np.int32)\n",
    "data,label=read_img(path)\n",
    "#打乱顺序\n",
    "num_example=data.shape[0] # data.shape是(3029, 100, 100, 3)\n",
    "arr=np.arange(num_example)# 创建等差数组 0，1，...,3028\n",
    "np.random.shuffle(arr)# 打乱顺序\n",
    "data=data[arr]\n",
    "label=label[arr]\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "personal-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=data\n",
    "train_labels=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "above-preparation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "gentle-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 100, 100,3).astype('float32')\n",
    "print(train_labels[0])\n",
    "plt.imshow(train_images[0, :, :], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "class Dense(layers.Layer):\n",
    "    def __init__(self, input_dim, units):\n",
    "        super(Dense,self).__init__()\n",
    "        # initializer = tf.initializers.glorot_uniform()\n",
    "        initializer = tf.initializers.glorot_normal()\n",
    "        self.w = tf.Variable(initial_value=initializer(shape=(input_dim,units),dtype=tf.float32),trainable=True)\n",
    "        self.b = tf.Variable(initial_value=tf.zeros(shape=(1,units),dtype=tf.float32),trainable=True)#节点的偏置也是行向量 才可以正常计算 即对堆叠的batch 都是加载单个batch内\n",
    "    @tf.function\n",
    "    def call(self,x,training=True):\n",
    "        if training == True:\n",
    "            y = tf.matmul(x,self.w)+self.b\n",
    "            return y\n",
    "        else:\n",
    "            y = tf.matmul(x,self.w)+self.b\n",
    "            return y \n",
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.dense1 = Dense(100*100*3,128)\n",
    "        self.dense2= Dense(128,32)\n",
    "        self.dense3 = Dense(32,1)\n",
    "    @tf.function\n",
    "    def call(self,x,training=True):\n",
    "        \"\"\"\n",
    "        batch*dim+batch*10 在index_1维度组合 其余维度不变\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x,[-1,30000]) #reshape 不改变原始的元素顺序 这很重要 防止变形时变成转置 忽略batch大小  只关注后面的维度一致\n",
    "        if training == True:\n",
    "            l1_out = tf.nn.relu(self.dense1(x,training))\n",
    "            l2_out = tf.nn.relu(self.dense2(l1_out,training))\n",
    "            l3_out = tf.nn.sigmoid(self.dense3(l2_out,training))\n",
    "            return l3_out\n",
    "        else:\n",
    "            l1_out = tf.nn.relu(self.dense1(x,training))\n",
    "            l2_out = tf.nn.relu(self.dense2(l1_out,training))\n",
    "            l3_out = self.dense3(l2_out,training) #!!!!!! WGAN  判别器不能加sigmoid \n",
    "            # l3_out = tf.nn.sigmoid(self.dense3(l2_out,training))\n",
    "            return l3_out\n",
    "    @tf.function       \n",
    "    def to_clip(self):\n",
    "        for weight in self.trainable_variables:\n",
    "            weight.assign(tf.clip_by_value(weight,clip_value_min=-0.01,clip_value_max=0.01))\n",
    "d = Discriminator()\n",
    "x = train_images[0:2, :, :]\n",
    "print(d(x,training=False))#行向量统一输入  而batch是行向量在列方向堆叠后的矩阵 \n",
    "print(len(d.trainable_variables))\n",
    "\n",
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.dense1 = Dense(100,32)\n",
    "        self.dense2 = Dense(32,128)\n",
    "        self.dense3 = Dense(128,30000)\n",
    "    @tf.function\n",
    "    def call(self,x,training=True):\n",
    "        if training == True:\n",
    "            l1_out = tf.nn.relu(self.dense1(x,training))\n",
    "            l2_out = tf.nn.relu(self.dense2(l1_out,training))\n",
    "            l3 = tf.nn.sigmoid(self.dense3(l2_out,training))\n",
    "        else:\n",
    "            l1_out = tf.nn.relu(self.dense1(x,training))\n",
    "            l2_out = tf.nn.relu(self.dense2(l1_out,training))\n",
    "            l3 = tf.nn.sigmoid(self.dense3(l2_out,training))\n",
    "        l3_out = tf.reshape(l3,[-1,100,100,3])\n",
    "        return l3_out\n",
    "\n",
    "g = Generator()\n",
    "z = tf.random.normal((1,100))\n",
    "image = g(z,training=False)\n",
    "#plt.imshow(tf.reshape(image,(100,100,3)), cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "print(d(image,training=False))\n",
    "\n",
    "def d_loss(real_output, fake_output):\n",
    "    total_loss = -tf.reduce_mean(real_output)+tf.reduce_mean(fake_output)#用batch 均值逼近期望 然后依据公式 max  所以取反  -E(real)+E(fake)  做min\n",
    "    return total_loss\n",
    "def g_loss(fake_output):\n",
    "    return -tf.reduce_mean(fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=3e-4,epsilon=1e-10)\n",
    "discriminator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=3e-4,epsilon=1e-10)\n",
    "\n",
    "EPOCHS = 400\n",
    "BATCH_SIZE = 128\n",
    "z_dim = 100\n",
    "num_examples_to_generate = 100\n",
    "seed = tf.random.normal([num_examples_to_generate, z_dim],mean=0.0,stddev=1.0)\n",
    "# seed = tf.random.uniform([num_examples_to_generate, z_dim],-1.0,1.0)\n",
    "\n",
    "@tf.function\n",
    "def D_train_step(images,labels):\n",
    "    z = tf.random.normal([images.shape[0], z_dim],mean=0.0,stddev=1.0)\n",
    "    # z = tf.random.uniform([images.shape[0], z_dim],-1.0,1.0)\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        generated_images = g(z,training=True)\n",
    "        real_output = d(images,training=True)\n",
    "        fake_output = d(generated_images,training=True)\n",
    "        disc_loss = d_loss(real_output,fake_output)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, d.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, d.trainable_variables))\n",
    "    d.to_clip()\n",
    "\n",
    "@tf.function\n",
    "def G_train_step(images,labels):\n",
    "    z = tf.random.normal([images.shape[0],z_dim],mean=0.0,stddev=1.0)\n",
    "    # z = tf.random.uniform([images.shape[0], z_dim],-1.0,1.0)\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = g(z,training=True)\n",
    "        fake_output = d(generated_images ,training=True)\n",
    "        gen_loss = g_loss(fake_output)\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, g.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, g.trainable_variables))\n",
    "\n",
    "def train(train_images,train_labels,epochs):\n",
    "    break_flag = 0\n",
    "    index = list(range(train_images.shape[0]))\n",
    "    np.random.shuffle(index)\n",
    "    train_images = train_images[index]\n",
    "    train_labels = train_labels[index]\n",
    "    images_batches = iter(tf.data.Dataset.from_tensor_slices(train_images).batch(BATCH_SIZE))\n",
    "    labels_batches = iter(tf.data.Dataset.from_tensor_slices(train_labels).batch(BATCH_SIZE))\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        while True:\n",
    "            for i in range(5):\n",
    "                try:\n",
    "                    x_real_bacth = next(images_batches)\n",
    "                    y_label_bacth = next(labels_batches)\n",
    "                    D_train_step(x_real_bacth,y_label_bacth)\n",
    "                except StopIteration:\n",
    "                    del images_batches\n",
    "                    del labels_batches\n",
    "                    np.random.shuffle(index)\n",
    "                    train_images = train_images[index]\n",
    "                    train_labels = train_labels[index]\n",
    "                    images_batches = iter(tf.data.Dataset.from_tensor_slices(train_images).batch(BATCH_SIZE))\n",
    "                    labels_batches = iter(tf.data.Dataset.from_tensor_slices(train_labels).batch(BATCH_SIZE))\n",
    "                    break_flag = 1\n",
    "                    break\n",
    "            if break_flag == 0: # 判别器训练5次 然后进行一次生成器\n",
    "                G_train_step(x_real_bacth,y_label_bacth)\n",
    "            else:\n",
    "                break_flag = 0\n",
    "                break\n",
    "        generate_and_save_images(g,epoch + 1,seed)\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input,training=False)\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    predictions=np.array(predictions)*255.0\n",
    "    for i in range(predictions.shape[0]):\n",
    "        #print(predictions[i])\n",
    "        newtqm=Image.fromarray(predictions[i].astype(np.uint8))\n",
    "        newtqm.save('./WGAN/'+str(epoch) + \"_\" + str(i) + \".png\")\n",
    "        #plt.subplot(10,10,i+1)\n",
    "        #plt.imshow(tf.reshape(predictions[i,:],shape=(100,100,3))*255.0, cmap='gray')\n",
    "        #plt.axis('off')\n",
    "    \n",
    "    #plt.savefig('./WGAN/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    #plt.close()\n",
    "\n",
    "print(time)\n",
    "train(train_images,train_labels,EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
